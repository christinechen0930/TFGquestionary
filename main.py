import os
import torch
import requests
import streamlit as st
from sentence_transformers import SentenceTransformer, util
import fitz  # PyMuPDF
from tavily import TavilyClient
import re

# ====== è¨­å®š API Key ======
TAVILY_API_KEY = st.secrets["TAVILY_API_KEY"]
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
tavily_client = TavilyClient(api_key=TAVILY_API_KEY)

# ====== é é¢è¨­å®š ======
st.set_page_config(page_title="ğŸŒ¿ ç¶ åœ’äº‹å‹™è©¢å•æ¬„", page_icon="ğŸŒ±", layout="centered")

# ====== åŠ è¼‰æ¨¡å‹ ======
@st.cache_resource
def load_model():
    return SentenceTransformer("sentence-transformers/multi-qa-MiniLM-L6-cos-v1")

model = load_model()

# ====== æ¸…ç†æ–‡å­— ======
def clean_and_split_text(text):
    text = re.sub(r"\s+", " ", text)
    text = re.sub(r"ç¬¬\s*\d+\s*é ", "", text)
    paragraphs = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ])', text)
    return [p.strip() for p in paragraphs if len(p.strip()) > 10]

# ====== è®€å– PDF æª”å…§å®¹ ======
def read_pdf(file_path):
    try:
        doc = fitz.Document(file_path)
        all_paragraphs = []
        for page in doc:
            text = page.get_text()
            all_paragraphs.extend(clean_and_split_text(text))
        return all_paragraphs
    except Exception as e:
        return [f"è®€å– PDF éŒ¯èª¤ï¼š{str(e)}"]

# ====== æœå°‹èˆ‡ä¸‹è¼‰ PDFï¼ˆä¿ç•™ URLï¼‰ ======
def search_and_download_pdfs(keyword):
    query = f"site:fg.tp.edu.tw {keyword} filetype:pdf"
    try:
        response = tavily_client.search(query)
    except Exception as e:
        return f"âŒ æœå‹™éŒ¯èª¤ï¼š{e}"

    results = [r for r in response.get("results", []) if r["url"].endswith(".pdf")]
    if not results:
        return "âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„ PDF æª”æ¡ˆï¼"

    pdf_data = []
    for i, r in enumerate(results):
        try:
            url = r["url"]
            filename = f"downloads/{keyword}_{i+1}.pdf"
            pdf_bytes = requests.get(url, timeout=10).content
            with open(filename, "wb") as f:
                f.write(pdf_bytes)
            pdf_data.append((filename, url))
        except Exception as e:
            return f"âŒ ä¸‹è¼‰å¤±æ•—ï¼š{url}ï¼ŒéŒ¯èª¤ï¼š{e}"

    return pdf_data

# ====== æ“·å–ç›¸é—œå…§å®¹ ======
def retrieve_relevant_content(task, paragraphs):
    paragraph_embeddings = model.encode(paragraphs, convert_to_tensor=True)
    query_embedding = model.encode(task, convert_to_tensor=True)
    scores = util.pytorch_cos_sim(query_embedding, paragraph_embeddings)[0]
    top_k = min(10, len(paragraphs))
    top_results = torch.topk(scores, k=top_k)
    return "\n".join([paragraphs[idx] for idx in top_results.indices])

# ====== æ•´åˆå›ç­” ======
def generate_response_combined(task, keyword, file=None):
    if not keyword.strip() and not file:
        return "âŒ è«‹è¼¸å…¥é—œéµå­—æˆ–ä¸Šå‚³ PDF"

    if file:
        paragraphs = read_pdf(file)
        sources = [file.name]
        urls = []
    else:
        result = search_and_download_pdfs(keyword)
        if isinstance(result, str):
            return result
        paragraphs = []
        sources = []
        urls = []
        for local_path, url in result:
            paragraphs.extend(read_pdf(local_path))
            sources.append(os.path.basename(local_path))
            urls.append(url)

    if not paragraphs or "éŒ¯èª¤" in paragraphs[0]:
        return paragraphs[0]

    relevant = retrieve_relevant_content(task, paragraphs)
    if not relevant.strip():
        return "âŒ æ‰¾ä¸åˆ°èˆ‡å•é¡Œç›¸é—œçš„å…§å®¹ï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚"

    source_links = "\n".join(
        [f"- [{name}]({url})" for name, url in zip(sources, urls)]
    ) if urls else f"- ä½¿ç”¨è€…ä¸Šå‚³ï¼š{sources[0]}"

    prompt = f"""
ä½ æ˜¯ä¸€ä½äº†è§£åŒ—ä¸€å¥³ä¸­è¡Œæ”¿æµç¨‹èˆ‡æ ¡å…§äº‹å‹™çš„è¼”å°è€å¸«ï¼Œè«‹æ ¹æ“šä¸‹æ–¹æä¾›çš„æ–‡ä»¶å…§å®¹å”åŠ©å›ç­”å•é¡Œã€‚
å›ç­”è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸¦ä»¥æ¢åˆ—å¼æˆ–æ‘˜è¦æ–¹å¼ç°¡æ½”è¡¨é”ã€‚

å•é¡Œï¼š{task}

ç›¸é—œå…§å®¹ï¼š
{relevant}

ä¾†æºæ¸…å–®ï¼š
{source_links}
    """

    api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent"
    headers = {"Content-Type": "application/json"}
    payload = {"contents": [{"role": "user", "parts": [{"text": prompt}]}]}

    try:
        res = requests.post(f"{api_url}?key={GEMINI_API_KEY}", json=payload, headers=headers)
        if res.status_code == 200:
            data = res.json()
            text = data["candidates"][0]["content"]["parts"][0]["text"]
            return text + "\n\n---\n### ğŸ“„ ä¾†æº PDF æ–‡ä»¶\n" + source_links
        else:
            return f"âŒ éŒ¯èª¤ï¼š{res.status_code} - {res.text}"
    except Exception as e:
        return f"âŒ è«‹æ±‚å¤±æ•—ï¼š{e}"

# ====== Streamlit ä»‹é¢ ======
st.title("ğŸŒ± ç¶ åœ’äº‹å‹™è©¢å•æ¬„")
task = st.text_input("è¼¸å…¥è©¢å•äº‹é …", "ä¾‹å¦‚ï¼šå¦‚ä½•ç”³è«‹äº¤æ›å­¸ç”Ÿï¼Ÿ")
keyword = st.text_input("è¼¸å…¥é—œéµå­—ï¼ˆè‡ªå‹•æœå°‹åŒ—ä¸€å¥³ PDFï¼‰", "ä¾‹å¦‚ï¼šæ‹›ç”Ÿç°¡ç« ")
file = st.file_uploader("æˆ–ä¸Šå‚³ PDF", type=["pdf"])

if st.button("ç”Ÿæˆå›ç­”"):
    with st.spinner("è™•ç†ä¸­ï¼Œè«‹ç¨å€™..."):
        result = generate_response_combined(task, keyword, file)
    st.success("å®Œæˆï¼")
    st.markdown(result)
